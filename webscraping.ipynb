{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a688d0-b05b-4239-957e-f77e3e86516b",
   "metadata": {},
   "source": [
    "# Web Scrapping \n",
    "# for getting real time data from any website\n",
    "# four basic steps\n",
    "#    ->sending a http get request to url for webpage usig request library\n",
    "#    ->Fetching and parsing the data using beautifulsoup and maintain the datain dict/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a43a60-3fc0-4a0d-a9c4-5369ab793beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from requests) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf024756-dc64-4c43-8544-6f7f25da7400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (0.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ec8c56-e467-44bd-9302-d2e80b5b1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package bs4:\n",
      "\n",
      "NAME\n",
      "    bs4 - Beautiful Soup Elixir and Tonic - \"The Screen-Scraper's Friend\".\n",
      "\n",
      "DESCRIPTION\n",
      "    http://www.crummy.com/software/BeautifulSoup/\n",
      "    \n",
      "    Beautiful Soup uses a pluggable XML or HTML parser to parse a\n",
      "    (possibly invalid) document into a tree representation. Beautiful Soup\n",
      "    provides methods and Pythonic idioms that make it easy to navigate,\n",
      "    search, and modify the parse tree.\n",
      "    \n",
      "    Beautiful Soup works with Python 3.6 and up. It works better if lxml\n",
      "    and/or html5lib is installed.\n",
      "    \n",
      "    For more than you ever wanted to know about Beautiful Soup, see the\n",
      "    documentation: http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    builder (package)\n",
      "    css\n",
      "    dammit\n",
      "    diagnose\n",
      "    element\n",
      "    formatter\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    bs4.element.Tag(bs4.element.PageElement)\n",
      "        BeautifulSoup\n",
      "    \n",
      "    class BeautifulSoup(bs4.element.Tag)\n",
      "     |  BeautifulSoup(markup='', features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, element_classes=None, **kwargs)\n",
      "     |  \n",
      "     |  A data structure representing a parsed HTML or XML document.\n",
      "     |  \n",
      "     |  Most of the methods you'll call on a BeautifulSoup object are inherited from\n",
      "     |  PageElement or Tag.\n",
      "     |  \n",
      "     |  Internally, this class defines the basic interface called by the\n",
      "     |  tree builders when converting an HTML/XML document into a data\n",
      "     |  structure. The interface abstracts away the differences between\n",
      "     |  parsers. To write a new tree builder, you'll need to understand\n",
      "     |  these methods as a whole.\n",
      "     |  \n",
      "     |  These methods will be called by the BeautifulSoup constructor:\n",
      "     |    * reset()\n",
      "     |    * feed(markup)\n",
      "     |  \n",
      "     |  The tree builder may call these methods from its feed() implementation:\n",
      "     |    * handle_starttag(name, attrs) # See note about return value\n",
      "     |    * handle_endtag(name)\n",
      "     |    * handle_data(data) # Appends to the current data node\n",
      "     |    * endData(containerClass) # Ends the current data node\n",
      "     |  \n",
      "     |  No matter how complicated the underlying parser is, you should be\n",
      "     |  able to build a tree using 'start tag' events, 'end tag' events,\n",
      "     |  'data' events, and \"done with data\" events.\n",
      "     |  \n",
      "     |  If you encounter an empty-element tag (aka a self-closing tag,\n",
      "     |  like HTML's <br> tag), call handle_starttag and then\n",
      "     |  handle_endtag.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BeautifulSoup\n",
      "     |      bs4.element.Tag\n",
      "     |      bs4.element.PageElement\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, markup='', features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, element_classes=None, **kwargs)\n",
      "     |      Constructor.\n",
      "     |      \n",
      "     |      :param markup: A string or a file-like object representing\n",
      "     |       markup to be parsed.\n",
      "     |      \n",
      "     |      :param features: Desirable features of the parser to be\n",
      "     |       used. This may be the name of a specific parser (\"lxml\",\n",
      "     |       \"lxml-xml\", \"html.parser\", or \"html5lib\") or it may be the\n",
      "     |       type of markup to be used (\"html\", \"html5\", \"xml\"). It's\n",
      "     |       recommended that you name a specific parser, so that\n",
      "     |       Beautiful Soup gives you the same results across platforms\n",
      "     |       and virtual environments.\n",
      "     |      \n",
      "     |      :param builder: A TreeBuilder subclass to instantiate (or\n",
      "     |       instance to use) instead of looking one up based on\n",
      "     |       `features`. You only need to use this if you've implemented a\n",
      "     |       custom TreeBuilder.\n",
      "     |      \n",
      "     |      :param parse_only: A SoupStrainer. Only parts of the document\n",
      "     |       matching the SoupStrainer will be considered. This is useful\n",
      "     |       when parsing part of a document that would otherwise be too\n",
      "     |       large to fit into memory.\n",
      "     |      \n",
      "     |      :param from_encoding: A string indicating the encoding of the\n",
      "     |       document to be parsed. Pass this in if Beautiful Soup is\n",
      "     |       guessing wrongly about the document's encoding.\n",
      "     |      \n",
      "     |      :param exclude_encodings: A list of strings indicating\n",
      "     |       encodings known to be wrong. Pass this in if you don't know\n",
      "     |       the document's encoding but you know Beautiful Soup's guess is\n",
      "     |       wrong.\n",
      "     |      \n",
      "     |      :param element_classes: A dictionary mapping BeautifulSoup\n",
      "     |       classes like Tag and NavigableString, to other classes you'd\n",
      "     |       like to be instantiated instead as the parse tree is\n",
      "     |       built. This is useful for subclassing Tag or NavigableString\n",
      "     |       to modify default behavior.\n",
      "     |      \n",
      "     |      :param kwargs: For backwards compatibility purposes, the\n",
      "     |       constructor accepts certain keyword arguments used in\n",
      "     |       Beautiful Soup 3. None of these arguments do anything in\n",
      "     |       Beautiful Soup 4; they will result in a warning and then be\n",
      "     |       ignored.\n",
      "     |       \n",
      "     |       Apart from this, any keyword arguments passed into the\n",
      "     |       BeautifulSoup constructor are propagated to the TreeBuilder\n",
      "     |       constructor. This makes it possible to configure a\n",
      "     |       TreeBuilder by passing in arguments, not just by saying which\n",
      "     |       one to use.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  decode(self, pretty_print=False, eventual_encoding='utf-8', formatter='minimal', iterator=None)\n",
      "     |      Returns a string or Unicode representation of the parse tree\n",
      "     |          as an HTML or XML document.\n",
      "     |      \n",
      "     |      :param pretty_print: If this is True, indentation will be used to\n",
      "     |          make the document more readable.\n",
      "     |      :param eventual_encoding: The encoding of the final document.\n",
      "     |          If this is None, the document will be a Unicode string.\n",
      "     |  \n",
      "     |  endData(self, containerClass=None)\n",
      "     |      Method called by the TreeBuilder when the end of a data segment\n",
      "     |      occurs.\n",
      "     |  \n",
      "     |  handle_data(self, data)\n",
      "     |      Called by the tree builder when a chunk of textual data is encountered.\n",
      "     |  \n",
      "     |  handle_endtag(self, name, nsprefix=None)\n",
      "     |      Called by the tree builder when an ending tag is encountered.\n",
      "     |      \n",
      "     |      :param name: Name of the tag.\n",
      "     |      :param nsprefix: Namespace prefix for the tag.\n",
      "     |  \n",
      "     |  handle_starttag(self, name, namespace, nsprefix, attrs, sourceline=None, sourcepos=None, namespaces=None)\n",
      "     |      Called by the tree builder when a new tag is encountered.\n",
      "     |      \n",
      "     |      :param name: Name of the tag.\n",
      "     |      :param nsprefix: Namespace prefix for the tag.\n",
      "     |      :param attrs: A dictionary of attribute values.\n",
      "     |      :param sourceline: The line number where this tag was found in its\n",
      "     |          source document.\n",
      "     |      :param sourcepos: The character position within `sourceline` where this\n",
      "     |          tag was found.\n",
      "     |      :param namespaces: A dictionary of all namespace prefix mappings \n",
      "     |          currently in scope in the document.\n",
      "     |      \n",
      "     |      If this method returns None, the tag was rejected by an active\n",
      "     |      SoupStrainer. You should proceed as if the tag had not occurred\n",
      "     |      in the document. For instance, if this was a self-closing tag,\n",
      "     |      don't call handle_endtag.\n",
      "     |  \n",
      "     |  insert_after(self, *args)\n",
      "     |      This method is part of the PageElement API, but `BeautifulSoup` doesn't implement\n",
      "     |      it because there is nothing before or after it in the parse tree.\n",
      "     |  \n",
      "     |  insert_before(self, *args)\n",
      "     |      This method is part of the PageElement API, but `BeautifulSoup` doesn't implement\n",
      "     |      it because there is nothing before or after it in the parse tree.\n",
      "     |  \n",
      "     |  new_string(self, s, subclass=None)\n",
      "     |      Create a new NavigableString associated with this BeautifulSoup\n",
      "     |      object.\n",
      "     |  \n",
      "     |  new_tag(self, name, namespace=None, nsprefix=None, attrs={}, sourceline=None, sourcepos=None, **kwattrs)\n",
      "     |      Create a new Tag associated with this BeautifulSoup object.\n",
      "     |      \n",
      "     |      :param name: The name of the new Tag.\n",
      "     |      :param namespace: The URI of the new Tag's XML namespace, if any.\n",
      "     |      :param prefix: The prefix for the new Tag's XML namespace, if any.\n",
      "     |      :param attrs: A dictionary of this Tag's attribute values; can\n",
      "     |          be used instead of `kwattrs` for attributes like 'class'\n",
      "     |          that are reserved words in Python.\n",
      "     |      :param sourceline: The line number where this tag was\n",
      "     |          (purportedly) found in its source document.\n",
      "     |      :param sourcepos: The character position within `sourceline` where this\n",
      "     |          tag was (purportedly) found.\n",
      "     |      :param kwattrs: Keyword arguments for the new Tag's attribute values.\n",
      "     |  \n",
      "     |  object_was_parsed(self, o, parent=None, most_recent_element=None)\n",
      "     |      Method called by the TreeBuilder to integrate an object into the parse tree.\n",
      "     |  \n",
      "     |  popTag(self)\n",
      "     |      Internal method called by _popToTag when a tag is closed.\n",
      "     |  \n",
      "     |  pushTag(self, tag)\n",
      "     |      Internal method called by handle_starttag when a tag is opened.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Reset this object to a state as though it had never parsed any\n",
      "     |      markup.\n",
      "     |  \n",
      "     |  string_container(self, base_class=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ASCII_SPACES = ' \\n\\t\\x0c\\r'\n",
      "     |  \n",
      "     |  DEFAULT_BUILDER_FEATURES = ['html', 'fast']\n",
      "     |  \n",
      "     |  NO_PARSER_SPECIFIED_WARNING = 'No parser was explicitly specified, so ...\n",
      "     |  \n",
      "     |  ROOT_TAG_NAME = '[document]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      A tag is non-None even if it has no contents.\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwargs)\n",
      "     |      Calling a Tag like a function is the same as calling its\n",
      "     |      find_all() method. Eg. tag('a') returns a list of all the A tags\n",
      "     |      found within this tag.\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |      A copy of a Tag must always be a deep copy, because a Tag's\n",
      "     |      children can only have one parent at a time.\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo, recursive=True)\n",
      "     |      A deepcopy of a Tag is a new Tag, unconnected to the parse tree.\n",
      "     |      Its contents are a copy of the old Tag's contents.\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Deleting tag[key] deletes all 'key' attributes for the tag.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true iff this Tag has the same name, the same attributes,\n",
      "     |      and the same contents (recursively) as `other`.\n",
      "     |  \n",
      "     |  __getattr__(self, tag)\n",
      "     |      Calling tag.subtag is the same as calling tag.find(name=\"subtag\")\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      tag[key] returns the value of the 'key' attribute for the Tag,\n",
      "     |      and throws an exception if it's not there.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterating over a Tag iterates over its contents.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The length of a Tag is the length of its list of contents.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true iff this Tag is not identical to `other`,\n",
      "     |      as defined in __eq__.\n",
      "     |  \n",
      "     |  __repr__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Setting tag[key] sets the value of the 'key' attribute for the\n",
      "     |      tag.\n",
      "     |  \n",
      "     |  __str__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Renders this PageElement as a Unicode string.\n",
      "     |  \n",
      "     |  childGenerator(self)\n",
      "     |      Deprecated generator.\n",
      "     |  \n",
      "     |  clear(self, decompose=False)\n",
      "     |      Wipe out all children of this PageElement by calling extract()\n",
      "     |         on them.\n",
      "     |      \n",
      "     |      :param decompose: If this is True, decompose() (a more\n",
      "     |          destructive method) will be called instead of extract().\n",
      "     |  \n",
      "     |  decode_contents(self, indent_level=None, eventual_encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this tag as a Unicode string.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many levels. (The formatter decides what a\n",
      "     |         'level' means in terms of spaces or other characters\n",
      "     |         output.) Used internally in recursive calls while\n",
      "     |         pretty-printing.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The tag is destined to be\n",
      "     |         encoded into this encoding. decode_contents() is _not_\n",
      "     |         responsible for performing that encoding. This information\n",
      "     |         is passed in so that it can be substituted in if the\n",
      "     |         document contains a <META> tag that mentions the document's\n",
      "     |         encoding.\n",
      "     |      \n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard Formatters.\n",
      "     |  \n",
      "     |  decompose(self)\n",
      "     |      Recursively destroys this PageElement and its children.\n",
      "     |      \n",
      "     |      This element will be removed from the tree and wiped out; so\n",
      "     |      will everything beneath it.\n",
      "     |      \n",
      "     |      The behavior of a decomposed PageElement is undefined and you\n",
      "     |      should never use one for anything, but if you need to _check_\n",
      "     |      whether an element has been decomposed, you can use the\n",
      "     |      `decomposed` property.\n",
      "     |  \n",
      "     |  encode(self, encoding='utf-8', indent_level=None, formatter='minimal', errors='xmlcharrefreplace')\n",
      "     |      Render a bytestring representation of this PageElement and its\n",
      "     |      contents.\n",
      "     |      \n",
      "     |      :param encoding: The destination encoding.\n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many levels. (The formatter decides what a\n",
      "     |         'level' means in terms of spaces or other characters\n",
      "     |         output.) Used internally in recursive calls while\n",
      "     |         pretty-printing.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard formatters.\n",
      "     |      :param errors: An error handling strategy such as\n",
      "     |          'xmlcharrefreplace'. This value is passed along into\n",
      "     |          encode() and its value should be one of the constants\n",
      "     |          defined by Python.\n",
      "     |      :return: A bytestring.\n",
      "     |  \n",
      "     |  encode_contents(self, indent_level=None, encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this PageElement as a bytestring.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many levels. (The formatter decides what a\n",
      "     |         'level' means in terms of spaces or other characters\n",
      "     |         output.) Used internally in recursive calls while\n",
      "     |         pretty-printing.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The bytestring will be in this encoding.\n",
      "     |      \n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard Formatters.\n",
      "     |      \n",
      "     |      :return: A bytestring.\n",
      "     |  \n",
      "     |  find(self, name=None, attrs={}, recursive=True, string=None, **kwargs)\n",
      "     |      Look in the children of this PageElement and find the first\n",
      "     |      PageElement that matches the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param recursive: If this is True, find() will perform a\n",
      "     |          recursive search of this PageElement's children. Otherwise,\n",
      "     |          only the direct children will be considered.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  findAll = find_all(self, name=None, attrs={}, recursive=True, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findChild = find(self, name=None, attrs={}, recursive=True, string=None, **kwargs)\n",
      "     |  \n",
      "     |  findChildren = find_all(self, name=None, attrs={}, recursive=True, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  find_all(self, name=None, attrs={}, recursive=True, string=None, limit=None, **kwargs)\n",
      "     |      Look in the children of this PageElement and find all\n",
      "     |      PageElements that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param recursive: If this is True, find_all() will perform a\n",
      "     |          recursive search of this PageElement's children. Otherwise,\n",
      "     |          only the direct children will be considered.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Returns the value of the 'key' attribute for the tag, or\n",
      "     |      the value given for 'default' if it doesn't have that\n",
      "     |      attribute.\n",
      "     |  \n",
      "     |  get_attribute_list(self, key, default=None)\n",
      "     |      The same as get(), but always returns a list.\n",
      "     |      \n",
      "     |      :param key: The attribute to look for.\n",
      "     |      :param default: Use this value if the attribute is not present\n",
      "     |          on this PageElement.\n",
      "     |      :return: A list of values, probably containing only a single\n",
      "     |          value.\n",
      "     |  \n",
      "     |  has_attr(self, key)\n",
      "     |      Does this PageElement have an attribute with the given name?\n",
      "     |  \n",
      "     |  has_key(self, key)\n",
      "     |      Deprecated method. This was kind of misleading because has_key()\n",
      "     |      (attributes) was different from __in__ (contents).\n",
      "     |      \n",
      "     |      has_key() is gone in Python 3, anyway.\n",
      "     |  \n",
      "     |  index(self, element)\n",
      "     |      Find the index of a child by identity, not value.\n",
      "     |      \n",
      "     |      Avoids issues with tag.contents.index(element) getting the\n",
      "     |      index of equal elements.\n",
      "     |      \n",
      "     |      :param element: Look for this PageElement in `self.contents`.\n",
      "     |  \n",
      "     |  prettify(self, encoding=None, formatter='minimal')\n",
      "     |      Pretty-print this PageElement as a string.\n",
      "     |      \n",
      "     |      :param encoding: The eventual encoding of the string. If this is None,\n",
      "     |          a Unicode string will be returned.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard formatters.\n",
      "     |      :return: A Unicode string (if encoding==None) or a bytestring\n",
      "     |          (otherwise).\n",
      "     |  \n",
      "     |  recursiveChildGenerator(self)\n",
      "     |      Deprecated generator.\n",
      "     |  \n",
      "     |  renderContents(self, encoding='utf-8', prettyPrint=False, indentLevel=0)\n",
      "     |      Deprecated method for BS3 compatibility.\n",
      "     |  \n",
      "     |  select(self, selector, namespaces=None, limit=None, **kwargs)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |      \n",
      "     |      This uses the SoupSieve library.\n",
      "     |      \n",
      "     |      :param selector: A string containing a CSS selector.\n",
      "     |      \n",
      "     |      :param namespaces: A dictionary mapping namespace prefixes\n",
      "     |         used in the CSS selector to namespace URIs. By default,\n",
      "     |         Beautiful Soup will use the prefixes it encountered while\n",
      "     |         parsing the document.\n",
      "     |      \n",
      "     |      :param limit: After finding this number of results, stop looking.\n",
      "     |      \n",
      "     |      :param kwargs: Keyword arguments to be passed into SoupSieve's\n",
      "     |         soupsieve.select() method.\n",
      "     |      \n",
      "     |      :return: A ResultSet of Tags.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  select_one(self, selector, namespaces=None, **kwargs)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |      \n",
      "     |      :param selector: A CSS selector.\n",
      "     |      \n",
      "     |      :param namespaces: A dictionary mapping namespace prefixes\n",
      "     |         used in the CSS selector to namespace URIs. By default,\n",
      "     |         Beautiful Soup will use the prefixes it encountered while\n",
      "     |         parsing the document.\n",
      "     |      \n",
      "     |      :param kwargs: Keyword arguments to be passed into Soup Sieve's\n",
      "     |         soupsieve.select() method.\n",
      "     |      \n",
      "     |      :return: A Tag.\n",
      "     |      :rtype: bs4.element.Tag\n",
      "     |  \n",
      "     |  smooth(self)\n",
      "     |      Smooth out this element's children by consolidating consecutive\n",
      "     |      strings.\n",
      "     |      \n",
      "     |      This makes pretty-printed output look more natural following a\n",
      "     |      lot of operations that modified the tree.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  children\n",
      "     |      Iterate over all direct children of this PageElement.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  css\n",
      "     |      Return an interface to the CSS selector API.\n",
      "     |  \n",
      "     |  descendants\n",
      "     |      Iterate over all children of this PageElement in a\n",
      "     |      breadth-first sequence.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  isSelfClosing\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  is_empty_element\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  self_and_descendants\n",
      "     |      Iterate over this PageElement and its children in a\n",
      "     |      breadth-first sequence.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  strings\n",
      "     |      Yield all strings of certain classes, possibly stripping them.\n",
      "     |      \n",
      "     |      :param strip: If True, all strings will be stripped before being\n",
      "     |          yielded.\n",
      "     |      \n",
      "     |      :param types: A tuple of NavigableString subclasses. Any strings of\n",
      "     |          a subclass not found in this list will be ignored. By\n",
      "     |          default, the subclasses considered are the ones found in\n",
      "     |          self.interesting_string_types. If that's not specified,\n",
      "     |          only NavigableString and CData objects will be\n",
      "     |          considered. That means no comments, processing\n",
      "     |          instructions, etc.\n",
      "     |      \n",
      "     |      :yield: A sequence of strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  parserClass\n",
      "     |  \n",
      "     |  string\n",
      "     |      Convenience property to get the single string within this\n",
      "     |      PageElement.\n",
      "     |      \n",
      "     |      TODO It might make sense to have NavigableString.string return\n",
      "     |      itself.\n",
      "     |      \n",
      "     |      :return: If this element has a single string child, return\n",
      "     |       value is that string. If this element has one child tag,\n",
      "     |       return value is the 'string' attribute of the child tag,\n",
      "     |       recursively. If this element is itself a string, has no\n",
      "     |       children, or has more than one child, return value is None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  DEFAULT_INTERESTING_STRING_TYPES = (<class 'bs4.element.NavigableStrin...\n",
      "     |  \n",
      "     |  EMPTY_ELEMENT_EVENT = <object object>\n",
      "     |  \n",
      "     |  END_ELEMENT_EVENT = <object object>\n",
      "     |  \n",
      "     |  START_ELEMENT_EVENT = <object object>\n",
      "     |  \n",
      "     |  STRING_ELEMENT_EVENT = <object object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  append(self, tag)\n",
      "     |      Appends the given PageElement to the contents of this one.\n",
      "     |      \n",
      "     |      :param tag: A PageElement.\n",
      "     |  \n",
      "     |  extend(self, tags)\n",
      "     |      Appends the given PageElements to this one's contents.\n",
      "     |      \n",
      "     |      :param tags: A list of PageElements. If a single Tag is\n",
      "     |          provided instead, this PageElement's contents will be extended\n",
      "     |          with that Tag's contents.\n",
      "     |  \n",
      "     |  extract(self, _self_index=None)\n",
      "     |      Destructively rips this element out of the tree.\n",
      "     |      \n",
      "     |      :param _self_index: The location of this element in its parent's\n",
      "     |         .contents, if known. Passing this in allows for a performance\n",
      "     |         optimization.\n",
      "     |      \n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  fetchNextSiblings = find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchPrevious = find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findAllNext = find_all_next(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findAllPrevious = find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findNext = find_next(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |  \n",
      "     |  findNextSibling = find_next_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |  \n",
      "     |  findNextSiblings = find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findParent = find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |  \n",
      "     |  findParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findPrevious = find_previous(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |  \n",
      "     |  findPreviousSibling = find_previous_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |  \n",
      "     |  findPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  find_all_next(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |      Find all PageElements that match the given criteria and appear\n",
      "     |      later in the document than this PageElement.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet containing PageElements.\n",
      "     |  \n",
      "     |  find_all_previous(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |      Look backwards in the document from this PageElement and find all\n",
      "     |      PageElements that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  find_next(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |      Find the first PageElement that matches the given criteria and\n",
      "     |      appears later in the document than this PageElement.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_next_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |      Find the closest sibling to this PageElement that matches the\n",
      "     |      given criteria and appears later in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the\n",
      "     |      online documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_next_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |      Find all siblings of this PageElement that match the given criteria\n",
      "     |      and appear later in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |      Find the closest parent of this PageElement that matches the given\n",
      "     |      criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |      Find all parents of this PageElement that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |      Look backwards in the document from this PageElement and find the\n",
      "     |      first PageElement that matches the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous_sibling(self, name=None, attrs={}, string=None, **kwargs)\n",
      "     |      Returns the closest sibling to this PageElement that matches the\n",
      "     |      given criteria and appears earlier in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous_siblings(self, name=None, attrs={}, string=None, limit=None, **kwargs)\n",
      "     |      Returns all siblings to this PageElement that match the\n",
      "     |      given criteria and appear earlier in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param string: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  format_string(self, s, formatter)\n",
      "     |      Format the given string using the given formatter.\n",
      "     |      \n",
      "     |      :param s: A string.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of the standard formatters.\n",
      "     |  \n",
      "     |  formatter_for_name(self, formatter)\n",
      "     |      Look up or create a Formatter for the given identifier,\n",
      "     |      if necessary.\n",
      "     |      \n",
      "     |      :param formatter: Can be a Formatter object (used as-is), a\n",
      "     |          function (used as the entity substitution hook for an\n",
      "     |          XMLFormatter or HTMLFormatter), or a string (used to look\n",
      "     |          up an XMLFormatter or HTMLFormatter in the appropriate\n",
      "     |          registry.\n",
      "     |  \n",
      "     |  getText = get_text(self, separator='', strip=False, types=<object object at 0x000002019A9F3F60>)\n",
      "     |  \n",
      "     |  get_text(self, separator='', strip=False, types=<object object at 0x000002019A9F3F60>)\n",
      "     |      Get all child strings of this PageElement, concatenated using the\n",
      "     |      given separator.\n",
      "     |      \n",
      "     |      :param separator: Strings will be concatenated using this separator.\n",
      "     |      \n",
      "     |      :param strip: If True, strings will be stripped before being\n",
      "     |          concatenated.\n",
      "     |      \n",
      "     |      :param types: A tuple of NavigableString subclasses. Any\n",
      "     |          strings of a subclass not found in this list will be\n",
      "     |          ignored. Although there are exceptions, the default\n",
      "     |          behavior in most cases is to consider only NavigableString\n",
      "     |          and CData objects. That means no comments, processing\n",
      "     |          instructions, etc.\n",
      "     |      \n",
      "     |      :return: A string.\n",
      "     |  \n",
      "     |  insert(self, position, new_child)\n",
      "     |      Insert a new PageElement in the list of this PageElement's children.\n",
      "     |      \n",
      "     |      This works the same way as `list.insert`.\n",
      "     |      \n",
      "     |      :param position: The numeric position that should be occupied\n",
      "     |         in `self.children` by the new PageElement.\n",
      "     |      :param new_child: A PageElement.\n",
      "     |  \n",
      "     |  nextGenerator(self)\n",
      "     |      # Old non-property versions of the generators, for backwards\n",
      "     |      # compatibility with BS3.\n",
      "     |  \n",
      "     |  nextSiblingGenerator(self)\n",
      "     |  \n",
      "     |  parentGenerator(self)\n",
      "     |  \n",
      "     |  previousGenerator(self)\n",
      "     |  \n",
      "     |  previousSiblingGenerator(self)\n",
      "     |  \n",
      "     |  replaceWith = replace_with(self, *args)\n",
      "     |  \n",
      "     |  replaceWithChildren = unwrap(self)\n",
      "     |  \n",
      "     |  replace_with(self, *args)\n",
      "     |      Replace this PageElement with one or more PageElements, keeping the\n",
      "     |      rest of the tree the same.\n",
      "     |      \n",
      "     |      :param args: One or more PageElements.\n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  replace_with_children = unwrap(self)\n",
      "     |  \n",
      "     |  setup(self, parent=None, previous_element=None, next_element=None, previous_sibling=None, next_sibling=None)\n",
      "     |      Sets up the initial relations between this element and\n",
      "     |      other elements.\n",
      "     |      \n",
      "     |      :param parent: The parent of this element.\n",
      "     |      \n",
      "     |      :param previous_element: The element parsed immediately before\n",
      "     |          this one.\n",
      "     |      \n",
      "     |      :param next_element: The element parsed immediately before\n",
      "     |          this one.\n",
      "     |      \n",
      "     |      :param previous_sibling: The most recently encountered element\n",
      "     |          on the same level of the parse tree as this one.\n",
      "     |      \n",
      "     |      :param previous_sibling: The next element to be encountered\n",
      "     |          on the same level of the parse tree as this one.\n",
      "     |  \n",
      "     |  unwrap(self)\n",
      "     |      Replace this PageElement with its contents.\n",
      "     |      \n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  wrap(self, wrap_inside)\n",
      "     |      Wrap this PageElement inside another one.\n",
      "     |      \n",
      "     |      :param wrap_inside: A PageElement.\n",
      "     |      :return: `wrap_inside`, occupying the position in the tree that used\n",
      "     |         to be occupied by `self`, and with `self` inside it.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  decomposed\n",
      "     |      Check whether a PageElement has been decomposed.\n",
      "     |      \n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  next\n",
      "     |      The PageElement, if any, that was parsed just after this one.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  next_elements\n",
      "     |      All PageElements that were parsed after this one.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  next_siblings\n",
      "     |      All PageElements that are siblings of this one but were parsed\n",
      "     |      later.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  parents\n",
      "     |      All PageElements that are parents of this PageElement.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  previous\n",
      "     |      The PageElement, if any, that was parsed just before this one.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  previous_elements\n",
      "     |      All PageElements that were parsed before this one.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  previous_siblings\n",
      "     |      All PageElements that are siblings of this one but were parsed\n",
      "     |      earlier.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  stripped_strings\n",
      "     |      Yield all strings in this PageElement, stripping them first.\n",
      "     |      \n",
      "     |      :yield: A sequence of stripped strings.\n",
      "     |  \n",
      "     |  text\n",
      "     |      Get all child strings of this PageElement, concatenated using the\n",
      "     |      given separator.\n",
      "     |      \n",
      "     |      :param separator: Strings will be concatenated using this separator.\n",
      "     |      \n",
      "     |      :param strip: If True, strings will be stripped before being\n",
      "     |          concatenated.\n",
      "     |      \n",
      "     |      :param types: A tuple of NavigableString subclasses. Any\n",
      "     |          strings of a subclass not found in this list will be\n",
      "     |          ignored. Although there are exceptions, the default\n",
      "     |          behavior in most cases is to consider only NavigableString\n",
      "     |          and CData objects. That means no comments, processing\n",
      "     |          instructions, etc.\n",
      "     |      \n",
      "     |      :return: A string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  nextSibling\n",
      "     |  \n",
      "     |  previousSibling\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  default = <object object>\n",
      "     |  \n",
      "     |  known_xml = None\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BeautifulSoup']\n",
      "    __copyright__ = 'Copyright (c) 2004-2023 Leonard Richardson'\n",
      "    __license__ = 'MIT'\n",
      "\n",
      "VERSION\n",
      "    4.12.2\n",
      "\n",
      "AUTHOR\n",
      "    Leonard Richardson (leonardr@segfault.org)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\hp\\onedrive\\desktop\\internship\\kits\\lib\\site-packages\\bs4\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#requests is widely used in web scrapping,accessind the API's\n",
    "#interacting with web servers/page.import requests\n",
    "import requests\n",
    "import bs4\n",
    "help(bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6964e87-0e01-4f9b-83c5-76693568f273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#connect to the url\n",
    "url = \"https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city\"\n",
    "data = requests.get(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3c8db2-fe8d-43b0-b02a-ea2067636b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debf4520-49f9-440a-a18a-ad0e3331d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where BeautifulSoup comes into action by getting the data\n",
    "soup = BeautifulSoup(data.content,'html')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102eba23-017d-42e3-80d5-f90f48317619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e58fe0-dfca-44e5-8254-3e1844f0d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82137ea6-7cee-42c2-88b6-92449c92bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e2ad47-f195-42c6-95bb-58473542fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1eeff99-ddc2-404b-9757-9215ba8602db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Residential Plot in Himaja Elite Vistas'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div',attrs={'class':'title-line'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4705a07a-a401-42fa-8c4e-d85f35f79b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Residential Plot'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a',attrs={'class':'typelink'}).span.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d647fe51-86ff-4051-93f0-60f64e92dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.52 Cr'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div',attrs={'data-type':'price-link'}).text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f655e569-b5af-49ef-9b60-526378988dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7200'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('td',attrs={'class':'size'}).text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca084af-c040-4fe3-a9ff-8afd9c79e509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kesarapalli'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span',attrs={'itemprop':'addressLocality'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdf00f6-6a7e-432a-9b49-49480f40e66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vijayawada'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span',attrs={'itemprop':'addressRegion'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4560f6d-0b7a-44ef-852c-73423bc4adf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('td',attrs={'class':'val'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42e4a369-89b7-42f2-a8ad-8d625bfcd504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NewNew/Resale'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('tr',attrs={'class':'hcol w44'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94296785-d723-4595-953b-a83373c2e352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 - 2 years old'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('ul',attrs={'class':'listing-details'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae3e2fd-c54e-4cb7-ba46-cf73508fa1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Property for Sale in Kesarapalli Vijayawada:A plot is available for sale in Himaja Constructions Vijaywada Elite Vistas, Kesarapalli, Vijayawada. It has an area of 7200 sqft and is priced at Rs. 2.52 cr . The amenities include skating rink, int...Developed by Himaja Constructions Vijaywada'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div',attrs={'class':'txt'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bbaa70c-84d0-4a64-9ae8-0cc922958493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Himaja Constructions P Ltd'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a',attrs={'class':'seller-name'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee4787d-c44a-49a4-82b6-1c7b48b2ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will extract details from the entire first page\n",
    "#find_all()\n",
    "#soup.find_all('div',attrs={'class':'title-line'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d95f6f8d-71b9-488f-adf0-9c58b70ba302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Residential Plot in Himaja Elite Vistas', 'Residential Plot in Himaja Elite Vistas', '2 BHK Apartment in Himaja Sri Hemadurga Jewel County', '3 BHK Apartment', 'Residential Plot', '2 BHK Apartment', '2 BHK Independent House', '2 BHK Apartment in Hycon Elite', '3 BHK Apartment', '3 BHK Independent Floor', '3 BHK Apartment', '2 BHK Apartment', '2 BHK Independent House', '3 BHK Independent Floor', '6 BHK Independent House', 'Residential Plot in Harivillu Fortune Legendary', 'Residential Plot', 'Residential Plot', '3 BHK Apartment in Pooja Tree Storey', '3 BHK Apartment in Sri Naga Sun Rise Enclave']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#as find_all() to be used for multiple entries we go for iterations\n",
    "a = soup.find_all('div',attrs={'class':'title-line'})\n",
    "names = [] #this list will have property names\n",
    "for i in a:\n",
    "    #print(i.text)\n",
    "    names.append(i.text)\n",
    "print(names)\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7fa101-cb3a-4a9c-a819-b397fefa27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kesarapalli', 'Kesarapalli', 'Gannavaram', 'Poranki', 'Kankipadu', 'Poranki', 'Kankipadu', 'Poranki', 'Gannavaram', 'Gunadala', 'Gollapudi', 'Enikepadu', 'Benz Circle', 'Vidhyadharpuram', 'Penamaluru', 'Kankipadu', 'Poranki', 'Kankipadu', 'Benz Circle', 'Gannavaram']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "b = soup.find_all('span',attrs={'itemprop':'addressLocality'})\n",
    "#optimized way -->List Comprehension\n",
    "#syntax is --> [exprsn for var in collection/function]\n",
    "places = [i.text for i in b]\n",
    "print(places)\n",
    "print(len(places))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4900c3f-0ec8-448b-82b5-b271926c2ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.52 Cr', '68.04 L', '45.57 L', '55.5 L', '15.5 L', '48 L', '50 L', '40 L', '59.86 L', '56 L', '89 L', '39 L', '59 L', '95 L', '1.1 Cr', '16.83 L', '33 L', '20 L', '1.66 Cr', '72 L']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#extracting price\n",
    "c = soup.find_all('div',attrs={'data-type':'price-link'})\n",
    "d = [i.text.strip() for i in c]\n",
    "print(d)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27eb0e19-530d-4510-9f84-d78f489a9cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252.0, 68.04, 45.57, 55.5, 15.5, 48.0, 50.0, 40.0, 59.86, 56.0, 89.0, 39.0, 59.0, 95.0, 110.00000000000001, 16.83, 33.0, 20.0, 166.0, 72.0]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Now we need to remove 'L' and 'Cr' from the above price\n",
    "#As prices are in Lakhs and Crores we start removing them\n",
    "Price = []\n",
    "for i in c:\n",
    "    i = i.text.strip()\n",
    "    if \"Cr\" in i:\n",
    "        i = i.replace(\" Cr\",'') #replacing with empty string\n",
    "        i = float(i) * 100 #converting into lakhs\n",
    "    else:\n",
    "        i = i.replace(\" L\",\"\")\n",
    "        i = float(i)\n",
    "    Price.append(i)\n",
    "print(Price)\n",
    "print(len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c253bc8-b731-4d34-b94b-e9ae1f3112d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7200', '1944', '1266', '1587', '1560', '1450', '1290', '1200', '1663', '1500', '2062', '1250', '1350', '1600', '3700', '1782', '1800', '1500', '2317', '1650']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "d = soup.find_all('td',attrs={'class':'size'})\n",
    "area = [i.text.strip() for i in d]\n",
    "print(area)\n",
    "print(len(area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c342b32a-0b97-4df6-83a9-17a523356fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Residential Plot', 'Residential Plot', 'Apartment', 'Apartment', 'Residential Plot', 'Apartment', 'Independent House', 'Apartment', 'Apartment', 'Independent Floor', 'Apartment', 'Apartment', 'Independent House', 'Independent Floor', 'Independent House', 'Residential Plot', 'Residential Plot', 'Residential Plot', 'Apartment', 'Apartment']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Getting the house type along with information about bathrooms/facing\n",
    "property_types = ['Apartment','Builder Floor','Villa',\n",
    "                  'Residential Plot','Independent House',\n",
    "                  'Independent Floor','Studio Apartment']\n",
    "f = soup.find_all('div',attrs={'class':'title-line'})\n",
    "Type = []\n",
    "for i in f:\n",
    "    i = i.text\n",
    "    for p_type in property_types:\n",
    "        if p_type in i:\n",
    "            Type.append(p_type)\n",
    "print(Type)\n",
    "print(len(Type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28858377-a427-4318-8d3b-4819e9a00763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '2', '3', '0', '2', '2', '2', '3', '3', '3', '2', '2', '3', '6', '0', '0', '0', '3', '3']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Now for the number of BHK we will replace Residential plot with '0'\n",
    "f = soup.find_all('div',attrs={'class':'title-line'})\n",
    "Rooms = []\n",
    "for i in f:\n",
    "    i = i.span.text\n",
    "    #print(i)\n",
    "    i = i.replace(\"Residential Plot\",'0').replace(' ','')\n",
    "    Rooms.append(i)\n",
    "print(Rooms)\n",
    "print(len(Rooms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01d3795e-4000-4c54-b250-6548508d5c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New', 'New', 'Ready to move', 'Ready to move', 'Resale', 'Ready to move', 'Under Construction', 'Ready to move', 'Ready to move', 'Ready to move', 'Ready to move', 'Ready to move', 'Ready to move', 'Under Construction', 'Ready to move', 'Resale', 'Resale', 'Resale', 'Under Construction', 'Ready to move']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#checking status type\n",
    "s = soup.find_all('td',attrs={'class':'val'})\n",
    "status = [i.text for i in s]\n",
    "print(status)\n",
    "print(len(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934cb931-2c84-448c-8ac0-9e47b958dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 - 2 years old', '1 - 2 years old', '3 - 4 years old2 BathroomsNew ', '3 BathroomsResale West facing', '7 - 8 years old2 open sidesEast facing', '2 BathroomsResale ', '2 BathroomsResale NorthEast facing', '2 BathroomsResale ', '3 BathroomsResale East facing', '3 BathroomsResale ', '3 BathroomsResale ', '2 BathroomsResale ', '2 BathroomsResale East facing', '3 BathroomsResale West facing', '7 - 8 years old7 BathroomsResale ', '1 - 2 years old', '1 open sidesWest facing', '7 - 8 years old', '3 BathroomsNew East facing', '2 - 3 years old3 BathroomsNew ']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#details of the property\n",
    "d = soup.find_all('ul',attrs={'class':'listing-details'})\n",
    "details = [i.text for i in d]\n",
    "print(details)\n",
    "print(len(details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2022af68-12dc-46a8-b4ef-6bd3ceda4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', 'None', 'None', 'West', 'East', 'None', 'NorthEast', 'None', 'East', 'None', 'None', 'None', 'East', 'West', 'None', 'None', 'West', 'None', 'East', 'None']\n",
      "[0, 0, 2, 3, 0, 2, 2, 2, 3, 3, 3, 2, 2, 3, 7, 0, 0, 0, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#So we finally separate Bathrooms and Type of Facing listings\n",
    "#Regular Expressions -->re\n",
    "import re #pattern matching\n",
    "d = soup.find_all('ul',attrs={'class':'listing-details'})\n",
    "Bathrooms = []\n",
    "Facing = []\n",
    "for i in d:\n",
    "    i = i.text\n",
    "    bathroom_count = re.findall(r'(\\d+) Bathrooms',i)#\\d -->digits\n",
    "    if bathroom_count:\n",
    "        Bathrooms.append(int(bathroom_count[0]))\n",
    "    else:\n",
    "        Bathrooms.append(0)\n",
    "    facing_direction = re.findall(r'(North|South|East|West|NorthEast|NorthWest|SouthEast|SouthWest) facing',\n",
    "                                  i)\n",
    "    if facing_direction:\n",
    "        Facing.append(facing_direction[0])\n",
    "    else:\n",
    "        Facing.append('None')\n",
    "print(Facing)\n",
    "print(Bathrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1670607-6284-4a42-8f44-78cc45406950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will use the same above logic to extract for the entire page\n",
    "#ipython -->Interactive Python\n",
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa45af43-20bb-44c7-9279-0ed98c374fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=1\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=2\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=3\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=4\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=5\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=6\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=7\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=8\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=9\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=10\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=11\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=12\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=13\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=14\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=15\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=16\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=17\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=18\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=19\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=20\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=21\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=22\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=23\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=24\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=25\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=26\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=27\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=28\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=29\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=30\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=31\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=32\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=33\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=34\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=35\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=36\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=37\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=38\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=39\n",
      "https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=40\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?page=\"\n",
    "for i in range(1,41):\n",
    "    url = base_url+str(i)\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed1acca1-4f8f-4cb5-8252-7fead8106561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "217f076b-c12b-4504-9459-66dade85c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271defc-bf00-4a7e-ae98-66b95a6763c4",
   "metadata": {},
   "source": [
    "# Scraping from multiple pages from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab07ce78-5883-45f7-a416-6acbb994ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Info from Page --> 53\n"
     ]
    }
   ],
   "source": [
    "Bedrooms = [];Bathrooms = []\n",
    "Location = [];Price = []\n",
    "Size = [];Status = []\n",
    "Facing = [];Type = []\n",
    "\n",
    "property_types = ['Apartment', 'Independent House',\n",
    "                  'Independent Floor',\n",
    "                  'Villa', 'Studio Apartment',\n",
    "                  'Residential Plot', 'Builder Floor']\n",
    "\n",
    "for i in range(1, 54):\n",
    "  url = f'https://www.makaan.com/vijayawada-residential-property/buy-property-in-vijayawada-city?propertyType=apartment,builder-floor,villa,residential-plot,independent-house,studio-apartment&page={i}'\n",
    "  print(f'Scraping Info from Page --> {i}')\n",
    "  clear_output(wait=True)\n",
    "  time.sleep(3) #waiting time to move from one page to other\n",
    "\n",
    "  d = requests.get(url)\n",
    "  soup = BeautifulSoup(d.content, 'html')\n",
    "\n",
    "  a = soup.find_all('a', attrs={'class':'typelink'})\n",
    "  for i in a:\n",
    "    i = i.span.text #you need only number which is present in start\n",
    "    i = i.replace('Residential Plot', '0').replace(' ', '')\n",
    "    Bedrooms.append(i)\n",
    "\n",
    "  b = soup.find_all('span', attrs={'itemprop':'addressLocality'})\n",
    "  for i in b:\n",
    "    Location.append(i.text)\n",
    "\n",
    "  c = soup.find_all('div', attrs={'data-type':'price-link'})\n",
    "  for i in c:\n",
    "    i = i.text.strip()\n",
    "    if 'Cr' in i:\n",
    "      i = i.replace(' Cr', '')\n",
    "      i = float(i) * 100 #converting into Lakhs\n",
    "    else:\n",
    "      i = i.replace(' L', '')\n",
    "      i = float(i)\n",
    "    Price.append(i)\n",
    "\n",
    "  #Extracting Area\n",
    "  d = soup.find_all('td', attrs={'class':'size'})\n",
    "  for i in d:\n",
    "    i = i.text.strip()\n",
    "    Size.append(i)\n",
    "\n",
    "  #Extracting construction status\n",
    "  e = soup.find_all('td', attrs={'class':'val'})\n",
    "  for i in e:\n",
    "    i = i.text\n",
    "    Status.append(i)\n",
    "\n",
    "  #Extracting Bathrooms and Facing Type\n",
    "  f = soup.find_all('ul', attrs={'class':'listing-details'})\n",
    "  for i in f:\n",
    "    i = i.text\n",
    "    bathroom_count = re.findall(r'(\\d+) Bathrooms', i)\n",
    "    if bathroom_count:\n",
    "      Bathrooms.append(int(bathroom_count[0]))\n",
    "    else:\n",
    "      Bathrooms.append('0')\n",
    "    facing_direction = re.findall(r'(North|South|East|West|NorthEast|NorthWest|SouthEast|SouthWest) facing', i)\n",
    "    if facing_direction:\n",
    "      Facing.append(facing_direction[0])\n",
    "    else:\n",
    "      Facing.append('None')\n",
    "\n",
    "  g = soup.find_all('div', attrs={'class':'title-line'})\n",
    "  for i in g:\n",
    "    i = i.text\n",
    "    for p_type in property_types:\n",
    "      if p_type in i:\n",
    "        Type.append(p_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca750b8-d851-4692-8783-ecbef901d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Bathrooms))\n",
    "print(len(Bedrooms))\n",
    "print(len(Status))\n",
    "print(len(Size))\n",
    "print(len(Location))\n",
    "print(len(Price))\n",
    "print(len(Facing))\n",
    "print(len(Type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e63bc89-804d-4c9e-96e7-9c3f11e88834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a dataframe from above data\n",
    "data_dict = {'Bedrooms':Bedrooms,\n",
    "            'Bathrooms':Bathrooms,\n",
    "            'Status':Status,\n",
    "            'Size':Size,\n",
    "            'Location':Location,\n",
    "            'Price':Price,\n",
    "            'Facing':Facing,\n",
    "            'Type':Type}\n",
    "#data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b901094-a877-481e-9490-343a599931ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      7\u001b[0m     data_dict[key] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m (max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_dict[key]))\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m data\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#data.isnull().sum()\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\internship\\kits\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\internship\\kits\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\internship\\kits\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\internship\\kits\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#Now as we have different values in all columns we write a logic\n",
    "#to create a dataframe keeping max_length as 1070 in above case\n",
    "import pandas as pd\n",
    "max_length = 1070 #dependng on your data scraped above\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] += [None] * (max_length - len(data_dict[key]))\n",
    "\n",
    "data = pd.DataFrame(data_dict)\n",
    "data\n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0ffd6-3ece-4264-861d-e518170432e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4741f-3674-4c21-abc7-89f906423886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have created missing values in all other columns so we drop those values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c185a80-1425-4025-ad61-f2695a5c25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f2b8c-65b8-4512-92c0-ccde35ccfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we get the final data we perform descriptive statistical information and then check for\n",
    "#outliers\n",
    "type(data)\n",
    "#data.describe()\n",
    "#data.describe(include=\"all\")\n",
    "data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a1abd-dbff-4bd4-91b1-755fadedaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before getting into removal of outliers let's have a\n",
    "#complete overview of all columns using plotly\n",
    "import plotly.express as px\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc10da-6f2c-4164-b675-b71e5a39659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.box(data) #As every column is having different type of data\n",
    "#we need to convert those categorical values to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d082c-00b4-4c10-9327-df8d92a506bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd92103-7b09-41f5-b792-78c46bf5a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Location'].unique()\n",
    "data['Location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57613565-a8d6-4cf4-8811-b52863091687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Facing'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21f98c-13e7-47c5-88f9-729c8e94838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cda47d-1d68-4130-8a18-3eababc496b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use sklearn for feature encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908216b2-95cd-4917-b5d9-c3a6f28158a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location'] = label.fit_transform(data['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c844f2-b9df-403e-b3a2-19449d1d178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Saketh','Codegnan','Obaid','Kesava']\n",
    "marks = [85,100,65,75]\n",
    "d = dict(zip(names,marks))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342ffbf-58ee-4907-b0a4-605129f51e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617c306-5bf4-44c7-8839-26940e0d371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location'] = label.fit_transform(data['Location'])\n",
    "encoded_to_original = dict(zip(label.transform(label.classes_),\n",
    "                               label.classes_))\n",
    "\n",
    "for encoded_label, original_value in encoded_to_original.items():\n",
    "  print(f'{encoded_label} - {original_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc28dd-f199-40d8-a7a5-26aaa6cb1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Status'] = label.fit_transform(data['Status'])\n",
    "encoded_to_original = dict(zip(label.transform(label.classes_),\n",
    "                               label.classes_))\n",
    "\n",
    "for encoded_label, original_value in encoded_to_original.items():\n",
    "  print(f'{encoded_label} - {original_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c30a8-e23d-4949-827a-e7d5a8b21b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Facing'] = label.fit_transform(data['Facing'])\n",
    "encoded_to_original = dict(zip(label.transform(label.classes_),\n",
    "                               label.classes_))\n",
    "\n",
    "for encoded_label, original_value in encoded_to_original.items():\n",
    "  print(f'{encoded_label} - {original_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ee88c-d843-477b-92d2-990c3bf30545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'] = label.fit_transform(data['Type'])\n",
    "encoded_to_original = dict(zip(label.transform(label.classes_),\n",
    "                               label.classes_))\n",
    "\n",
    "for encoded_label, original_value in encoded_to_original.items():\n",
    "  print(f'{encoded_label} - {original_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f18db2-02b5-454b-b493-6235703a7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788cc41-2c38-44ef-9fbc-292398115fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting object dtype into int dtype\n",
    "data['Bathrooms'] = data['Bathrooms'].astype('int64')\n",
    "data['Bedrooms'] = data['Bedrooms'].astype('int64')\n",
    "data['Size'] = data['Size'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78f6a7-54b2-4858-bead-d72819859c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "  if data[col].dtype == 'object':\n",
    "    data[col] = label.fit_transform(data[col])\n",
    "    encoded_to_original = dict(zip(label.transform(label.classes_),\n",
    "                                  label.classes_))\n",
    "    print(col,' = {')\n",
    "    for encoded_label, original_value in encoded_to_original.items():\n",
    "      print(f'\"{original_value}\" : {encoded_label}',end=',')\n",
    "    print('}')\n",
    "    print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ec2fa-2ad1-4fbc-ac05-6fc09429dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeeec43-fbe9-467a-bd41-893af51c5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()\n",
    "px.box(data,x='Facing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb289506-66f5-4e87-bfd0-e34c50dc4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers from the dataframe -->we will create a final dataframe\n",
    "def remove_outliers(df, threshold=3):\n",
    "    df_cleaned = df.copy() #copy of dataframe\n",
    "    #The threshold value determines how far from the first and third quartiles a data point must be to be considered an outlier\n",
    "    for col in df_cleaned.select_dtypes(include=['int64',\n",
    "                                               'float64']).columns:\n",
    "        Q1 = df_cleaned[col].quantile(0.25) #25th percentile\n",
    "        Q3 = df_cleaned[col].quantile(0.75) #75th percentile\n",
    "        IQR = Q3 - Q1 #InterQuantile Range\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        #Filter the DataFrame to keep only the rows where the\n",
    "        #column values are within the calculated bounds,\n",
    "        #effectively removing outliers\n",
    "        df_cleaned = df_cleaned[\n",
    "            (df_cleaned[col] >= lower_bound) &\n",
    "            (df_cleaned[col] <= upper_bound)\n",
    "        ]\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be53df-d7b3-4ec9-b0d7-3321bb41fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_percentage_check(df, threshold=3):\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    total_outliers = 0  # Initialize a variable to count total outliers.\n",
    "\n",
    "    for col in df_cleaned.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        Q1 = df_cleaned[col].quantile(0.25)\n",
    "        Q3 = df_cleaned[col].quantile(0.75)\n",
    "\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        outliers = (df_cleaned[col] < lower_bound) | (df_cleaned[col] > upper_bound)\n",
    "\n",
    "        total_outliers += outliers.sum()  # Count outliers in the current column.\n",
    "\n",
    "        df_cleaned = df_cleaned[~outliers]\n",
    "\n",
    "    percentage_outliers = (total_outliers / df.shape[0]) * 100  # Calculate the percentage of outliers.\n",
    "\n",
    "    return df_cleaned, percentage_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ac326-e6cc-4c31-874e-f50bffc00537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcc9f9-7d83-4c0a-9d44-1b181aebbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create a csv file from the above data\n",
    "#df.info()\n",
    "df.to_csv(\"House.csv\",index=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acc3f4-6705-4ac0-be68-5a183ad6b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bathrooms'] = df['Bathrooms'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e8229-60d3-495e-b0c0-86c979cef3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c09912-2f01-4ac0-acbe-005bfb95f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('House.csv')\n",
    "#data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4783ca-322a-4dc9-bedb-db9c97630998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02549f7b-df52-4fcd-8c67-85ed87285960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('House.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca210e1a-4030-4c9f-a88d-bf305a96501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a13efe-8280-4ef1-a67f-4add61f37545",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.arange(1,10).reshape(5,2),range(5)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a41f43-f806-432e-b880-21088085d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,p,q,r=train_test_split(a,b,random_state=1,test_size=0.3)\n",
    "w,p,q,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772801da-830b-4626-97a8-9f2fc9bebb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bcbc2-de47-4a6f-bf1e-cf9c86f2f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf126fb2-cab5-45c5-a0b7-e176a00c0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train),len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54777e3-7251-421d-ab32-9b594b94391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaf9cd-314c-4610-9630-2fa828213947",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0132059-f5a3-4b1d-baa8-944dcec28717",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=lin_reg.predict(x_test)#prediction values for y\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e538b-b804-4352-a21c-14b6a6c93e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b19b00-0ae6-4e80-add9-928492291d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa398551-4571-4589-8c82-edd77c3b3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression Metrics/Model Evaluation:\")\n",
    "print('R-Squared Error:',r2_score(y_test,y_preds))\n",
    "print(\"Mean squared error\",mean_squared_error(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170dd45-7058-480c-9ddd-62503bf5fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb7e38-970e-4ee2-a55d-9e3a795864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms=int(input('Enter no.of.bedrooms: '))\n",
    "bathrooms=int(input('Enter no.of.bathrooms: '))\n",
    "status=int(input('Enter status: '))\n",
    "size=int(input('Enter SQFT: '))\n",
    "location=int(input('Enter location: '))\n",
    "facing=int(input('Enter facing: '))\n",
    "Type=int(input('Enter type: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1d9b6-1c28-4273-a27e-8eb3c2e12175",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=np.array([[bedrooms,bathrooms,status\n",
    "                     ,size,location,facing,Type]])\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105a27d-ff1d-4282-891a-6d94d7207062",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=lin_reg.predict(user_input)[0]\n",
    "result.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff4838-8276-4c69-b5a2-8726ca04b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lin_reg,open('lin_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf38749-74bd-4fc3-a836-b3c6756fd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pickle.load(open('lin_model.pkl','rb'))\n",
    "user_input=np.array([[bedrooms,bathrooms,status\n",
    "                     ,size,location,facing,Type]])\n",
    "#user_input\n",
    "result=lin_reg.predict(user_input)[0].round(2)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85ca2f-02b9-4607-8415-9c2df79b1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051b03b-7e01-44c2-945f-29c279c8b75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
